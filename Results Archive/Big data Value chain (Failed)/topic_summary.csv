Topic,Count,Name,Representation,Representative_Docs
-1,21,-1_science_data science_data_skills,"['science', 'data science', 'data', 'skills', 'learning', 'education', 'project', 'knowledge', 'educational', 'training']","['The emerging data-driven economy (also defined as Industry 4.0 or simply 4IR), encompassing industry, research and business, requires new types of specialists that are able to support all stages of the data lifecycle from data production and input, to data processing and actionable results delivery, visualisation and reporting, which can be collectively defined as the Data Science family of professions. Data Science as a research and academic discipline provides a basis for Data Analytics and ML/AI applications. The education and training of the data related professions must reflect all multi-disciplinary knowledge and competences that are required from the Data Science and handling practitioners in modern, data-driven research and the digital economy. In the modern era, with ever faster technology changes, matched by strong skills demand, the Data Science education and training programme should be customizable and deliverable in multiple forms, tailored for different categories of professional roles and profiles. Referring to other publications by the authors on building customizable and interoperable Data Science curricula for different types of learners and target application domains, this paper is focused on defining a set of transversal competences and skills that are required from modern and future Data Science professions. These include workplace and professional skills that cover critical thinking, problem solving, and creativity required to work in highly automated and dynamic environment. The proposed approach is based on the EDISON Data Science Framework (EDSF) initially developed within the EU funded Project EDISON and currently being further developed in the EU funded MATES project and also the FAIRsFAIR projects.', 'Data Science is an emerging field of science, which requires a multi-disciplinary approach and is based on the Big Data and data intensive technologies that both provide a basis for effective use of the data driven research and economy models. Modern data driven research and industry require new types of specialists that are capable to support all stages of the data lifecycle from data production and input to data processing and actionable results delivery, visualisation and reporting, which can be jointly defined as the Data Science professions family. The education and training of Data Scientists currently lacks a commonly accepted, harmonized instructional model that reflects all multi-disciplinary knowledge and competences that are required from the Data Science practitioners in modern, data driven research and the digital economy. The educational model and approach should also solve different aspects of the future professionals that includes both theoretical knowledge and practical skills that must be supported by corresponding education infrastructure and educational labs environment. In modern conditions with the fast technology change and strong skills demand, the Data Science education and training should be customizable and delivered in multiple form, also providing sufficient data labs facilities for practical training. This paper discussed both aspects: building customizable Data Science curriculum for different types of learners and proposing a hybrid model for virtual labs that can combine local university facility and use cloud based Big Data and Data analytics facilities and services on demand. The proposed approach is based on using the EDISON Data Science Framework (EDSF) developed in the EU funded Project EDISON and CYCLONE cloud automation systems being developed in another EU funded project CYCLONE.', 'Emerging data driven economy including industry, research and business, requires new types of specialists that are capable to support all stages of the data lifecycle from data production and input to data processing and actionable results delivery, visualisation and reporting, which can be jointly defined as the Data Science professions family. Data Science is becoming a new recognised field of science that leverages the Data Analytics methods with the power of the Big Data technologies and Cloud Computing that both provide a basis for effective use of the data driven research and economy models. Data Science research and education require a multi-disciplinary approach and data driven/centric paradigm shift. Besides core professional competences and knowledge in Data Science, increasing digitalisation of Science and Industry also requires new type of workplace and professional skills that rise the importance of critical thinking, problem solving and creativity required to work in highly automated and dynamic environment. The education and training of the data related professions must reflect all multi-disciplinary knowledge and competences that are required from the Data Science and handling practitioners in modern, data driven research and the digital economy. In modern conditions with the fast technology change and strong skills demand, the Data Science education and training should be customizable and delivered in multiple forms, also providing sufficient lab facilities for practical training. This paper discusses aspects of building customizable and interoperable Data Science curricula for different types of learners and target application domains. The proposed approach is based on using the EDISON Data Science Framework (EDSF) initially developed in the EU funded Project EDISON and currently being maintained by the EDISON Community Initiative.']"
0,41,0_prediction_degradation_rul_health,"['prediction', 'degradation', 'rul', 'health', 'model', 'data', 'bearings', 'equipment', 'rul prediction', 'failure']","['Accurately predicting the remaining useful life (RUL) of bearings is quite significant for ensuring the operation reliability of wind turbines. Due to the limitation of real-world life cycle data, the accuracy of existing wind turbine RUL prediction methods needs to be improved. This article suggests a multisource domain meta transfer learning (MD-MTL)-based cross-scenario transferable RUL prediction method. The MD-MTL uses test rig data on multiple operating conditions to build up the prediction model and migrate the prediction knowledge to real wind turbines. In addition, a novel RUL prediction network based on a convolutional encoder and ProbSparse multihead attention decoder (CE-PSAD) is proposed for the improvement of prediction accuracy. It can extract key degradation features and long-term dependence relationships from raw vibration signals, and complete the precise mapping to RUL. The efficiency of the proposed method is proven based on two test rig datasets and two wind turbine bearing datasets.', 'Remaining useful life (RUL) prediction of rolling bearings is of paramount importance to various industrial applications. Recently, intelligent data-driven RUL prediction methods have achieved fruitful results. However, the existing methods heavily rely on the quality and quantity of the available data. For some critical bearings in industrial scenarios, the real run-to-failure data are insufficient, which impair the applicability of data-based methods for industrial practices. To address these issues, this article proposes a novel dynamic model-assisted RUL prediction approach for rolling bearing, in which sufficient simulation data are applied as the training data to solve the problem caused by insufficient real data. More specifically, a dynamic rolling bearing model is introduced for simulating the degradation process of physical structures. Then, a multilayer cross-domain transformer network is developed to implement RUL prediction and adapt the learned prediction knowledge from simulation to the actual measurements. Furthermore, a mutual information loss is utilized to preserve the generalized prediction knowledge of the measured data. The proposed approach can achieve a high RUL prediction accuracy with only limited measured data, which tackles the drawbacks of the existing data-driven methods. The experimental results of the rolling bearing degradation datasets demonstrate the effectiveness and superiority of the proposed RUL prediction approach.', 'Rolling bearing is an important component of rotating machinery equipment. Predictive maintenance can reduce unplanned maintenance expenditure and effectively improve the reliability of the equipment. The bearings produced in one batch may present completely different degradation trends, which increases the difficulty of tracking the degradation trend and predicting the remaining useful life (RUL) of bearings. Therefore, a RUL prediction method based on adaptive ensemble model is provided in this paper. First, an adaptive features integration technology is designed to construct a comprehensive health indicator with feature set in the time-frequency domain, which enhances the performance of health indicators to characterize the health status of bearings. Second, a dynamic ensemble model is further developed to predict RUL, which enhances the ability of the model to track different degradation trends and adaptively adjust the model parameters according to specific trend. A bearing life cycle dataset is applied to demonstrate the superiority the proposed approach.']"
1,794,1_data_big_big data_management,"['data', 'big', 'big data', 'management', 'system', 'which', 'model', 'information', 'security', 'value']","['This paper describes the general architecture and functional components of the cloud based Big Data Infrastructure (BDI). The proposed BDI architecture is based on the analysis of the emerging Big Data and data intensive technologies and supported by the definition of the Big Data Architecture Framework (BDAF) that defines the following components of the Big Data technologies: Big Data definition, Data Management including data lifecycle and data structures, Big Data Infrastructure (generically cloud based), Data Analytics technologies and platforms, and Big Data security, compliance and privacy. The paper provides example of requirements analysis and implementation of two bioinformatics use cases on cloud and using SlipStream based cloud applications deployment and management automation platform being developed in the CYCLONE project. The paper also refers to importance of standardisation of all components of BDAF and BDI and provides short overview of the NIST Big Data Interoperability Framework (BDIF). The paper discusses importance of automation of all stages of the Big Data applications developments, deployment and management and refers to existing cloud automation tools and new developments in the SlipStream cloud automation platform that allows multi-cloud applications deployment and management.', 'With the digital transformation, businesses and public administrations must change the place of data in the value chain to serve all areas of the business and open up information systems. The value of the knowledge extracted from this data is directly linked to the quality of data collection. Mobile devices are particularly suitable for reporting data. They are very widespread, very suitable and can be used at any time. These characteristics mean that the use of mobile support for data collection corresponds to a paradigm shift more than a simple new additional technology compared to the panoply of existing tools. The explosion of information sharing and data, which stems from our daily by these devices is stored mostly in the cloud servers. Thus, to reduce the number of data transferred and generated by mobile devices to the cloud servers, the edge computing allows to process data at the network edge where they are generated directly reducing certain characteristics of Big Data. Big data involves the collection of complex data on the “V” dimensions which describe the quantity and type of data collected, as well as their importance and relevance to the challenges of the requester. However, the smart data goes a step further and consist to extract from the data collected only the most relevant information for the client in order to make predictions. Our results show that using an intelligent data collection process in mobile computing could generate savings in terms of data storage and analysis at the cloud level.', 'In the realm of big data, the volume of research data in universities is expanding rapidly. However, the lack of data collaboration results in data isolation, hindering the realization of their potential value. This study aims to enhance data interoperability and promote data reuse by developing a comprehensive metadata scheme, which facilitates standardized descriptions of scientific data metadata throughout the entire process, from data generation to citation. Additionally, by delineating the data governance process encompassing data collection, processing and handling, archival and management, as well as data utilization and sharing, a data management cloud platform is established based on data reuse patterns. This platform incorporates features for data retrieval, storage and management, and data monitoring, ensuring the seamless continuity of research management efforts.']"
